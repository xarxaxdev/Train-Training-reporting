\section{Core malfunctions analysis / particularities}
\subsection{Implications on Encodings}

\subsubsection{Modularity}
A common issue when debugging an ASP problem is to figure out which choice rules or deductions may be the biggest timesink in your program. To debug this is usually complicated, and will in all likelihood discourage someone unfamiliar with the particularities of grounding and what is used beyond syntax. To draw a simile, I may not know all the secrets of a C++ compiler, but I can write a mediocre C++ code, with timestamps that allow me to figure what particular part of my program is slow, then iterate an improvement. This is the case for most programming languages, but no such straightforward approach exists in \textit{Clingo}.

By being allowed to selectively load a set of atoms (that have been generated dynamically), we can easily identify which atom generation is slowing down the program. Doing this is far from the most common way to debug these issues in your average \textit{Clingo} program, but it does respect the fact that \textit{Clingo} wants the solver to be solution-agnostic. 


\subsubsection{Window of grounding}
\label{sec:window}
The mechanics of malfunctions, have made us focus on trying to build an encoding that uses a window, rather than solving a specific instance problem. While the problem-agnostic nature usually focuses on direct problems that can be grounded and solved, when building an encoding for malfunctions, one realizes that all timestamps prior to the current are not necessary to reach a successful solution (neither the atoms used to indicate when a train is at a particular position at a particular time). As such one does not need to ground time values outside the window that has been calculated.

This also shows how to work around against the limitations of ASP; in problems where the horizon of events is too large one may just have too much grounding to do for it. Segmenting said problem seems like the obvious workaround around it, and opens up the possibility of unlimited running simulations. This definitely jumps outside \textit{Flatland}, but chip microcontrollers often work in an infinite-loop; windowed ASP could be a good use case.
  

\subsection{Our interests}
While a malfunction may not seem too complicated to work on, there is a huge variety of edge cases that can (and will) appear as one tries to write a working encoding. Not only that, multiple consecutive malfunctions may happen in a simulation, some of them at the same timestamp. This means that an encoding with a `leaky grounding` will not work on more malfunction-prone simulations. As such the first focus was to have a solution that actually worked for all edge cases was an important solution, as well as a solution that used the forementioned window of grounding. This initial solution was named \textbf{Graph} \footnote{https://github.com/FeignDeath/Train-Training/tree/main/asp/graph\_reschedule}. 


The forwarding of information allows, to pass finished representations instead of recomputing them. For that we will implement a second approach: \textbf{Graph\_naive}\footnote{https://github.com/FeignDeath/Train-Training/tree/main/asp/graph\_reschedule\_naive}. Opposed to the solution, passes as little information as possible and recomputes as much as possible. While this part is usually not the most time-costly part of the NP-natured problems that an ASP encoding solves, it is interesting nonetheless to study whether there are advantages of staticly reading rather than calculating. The difference may become relevant when one wants to work on a very big map representation; or when one decides to ground a more complex representation for the sake of simplifying the search space.


Finally, since the simulation itself is completely tied to iteratively going through the time, we found it interesting to study how an incremental solution tied to time would perform. Timesteps are a severe problem for grounding, thus any reduction, would be a good concept. To that end we implement an \textbf{Incremental}\footnote{https://github.com/FeignDeath/Train-Training/tree/main/asp/incremental} approach, which in theory should perform best, when many malfunctions happen, as it does not require a problematic estimate to expand the time, but can only ground as much as necessary.


We would have been interested in solution-resilience as well, since what a malfunction effectively is does some pruning in the solution space. But seeing as this would be our first usage of an optimize statement on top of the already complex implementation, and that we had opted rather for prolonging the allowed end timestamp in all of our experimentation, we thought it was beyond the scope of our research.



