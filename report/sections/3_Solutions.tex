
\section{Solutions}
Every encoding below uses an estimate of the horizon as window for its computations, which is passed from the flatland environments.
\color{green}
\subsection{Definitions}
To not reiterate the descriptions of the example files we are using for our properly-structured solution, I will be describing it here. While our solution is graph-based; it should be valid for other approaches. The respective files are:
\begin{itemize}
	\item  \textbf{input.lp} File that generates the base problem representation (a graph or other); with no choice rules.
	\item  \textbf{path.lp} File that uses choice rules to determine the path.
	\item  \textbf{output.lp} File that deduces, given the elected path, which action should be followed by each train; with no choice rules.
	\item  \textbf{malfunctions.lp} File that loads (selectively, according to the timestamp) and saves upon malfunction. Also where path implications from a malfunction should be deduced; with no choice rules.
\end{itemize}
\color{black} \color{gray} I would get rid of this. I think our structure is not important, as it adds nothing to the execution, for the order of lines does not matter. \color{black}
\color{blue}
\begin{itemize}
	\item make small section for it
	\item flatland and action saving and state machine problems
\end{itemize}
\color{black}


\subsection{Graph}
\noindent \textbf{Motivation} The basic concept is convert flatland instances into an abstract graph representation. The main difficulty lies therein, that in Flatland cells, are not the only thing constraining movement, but additionally a direction needs to either be tracked as additional information, or be merged into the graph. For this encoding we chose the second approach. To ensure a graph-like structure vertices are not defined by just the cell, but by the cell the train came from. This leads to a graph with directed edges and paths modelling the environment. This approach serves as a baseline for comparison, and a foundation to build upon with the other encodings.\\

\begin{figure}
\begin{minipage}[t]{0.45\textwidth}
    \centering
	\begin{tikzpicture}
		\draw[blue] (0,0.5) rectangle (1,1.5);
		\draw (0.5,0.5) -- (0.5,1.5);
		\draw (0.5,0.5) to[out=90,in=180] (1,1);
	
		\draw[blue] (3,1.5) rectangle (4,2.5);
		\draw (3.5,1.5) -- (3.5,2.5);
		\draw (3.5,1.5) to[out=90,in=180] (4,2);
		\draw (3,0.5) rectangle (4,1.5);
		\draw[-{Stealth},color=red,thick] (3.5,1.5) -- (3.5,1.7);
	
		\draw[blue] (4.5,0.5) rectangle (5.5,1.5);
		\draw (5,0.5) -- (5,1.5);
		\draw (5,0.5) to[out=90,in=180] (5.5,1);
		\draw (4.5,1.5) rectangle (5.5,2.5);
		\draw[-{Stealth},color=red,thick] (5,1.5) -- (5,1.3);
	
		\draw[blue] (6,0.5) rectangle (7,1.5);
		\draw (6.5,0.5) -- (6.5,1.5);
		\draw (6.5,0.5) to[out=90,in=180] (7,1);
		\draw (7,0.5) rectangle (8,1.5);
		\draw[-{Stealth},color=red,thick] (7,1) -- (6.8,1);
	
		\node at (0.2, 1.4) {At};
		\node at (3.2, 2.4) {At};
		\node at (4.7, 1.4) {At};
		\node at (6.2, 1.4) {At};
		\node at (3.35, 1.4) {Prev};
		\node at (4.85, 2.4) {Prev};
		\node at (7.35, 1.4) {Prev};
	
		\draw[->,thick] (1.5,1) -- (2.5,1);
	\end{tikzpicture}
    \caption{Cell to Graph}
    \label{fig:graph}
\end{minipage}
\end{figure}

\noindent \textbf{Implementation} To that end, the information from flatland is converted similar to Figure \ref{fig:graph}. The vertex predicates are \texttt{vertex(At,Prev)}, where \texttt{At} is the position of the train, and \texttt{Prev} is the previous position necessary to reach there. As the red arrows show, one could also replace \texttt{Prev} with the facing direction, when entering. Both contain the same information. Now, one cell is represented by up to 4 vertices. This is handled by introducing a predicate shared resources, to forbid conflicts.

This approach is a rudimentary one, representing agents and their position, for every timestep. As many papers deal with Multi Agent Pathfinding Problems on ASP, I will not go into more detail here, but instead skip to the adaption of malfunctions. (More Info on Solving MAPF with ASP: \cite{MAPF})\\

\noindent The secondary encoding handles malfunctions in three steps.

\textit{Reconstruction} relies on the previous encoding passing the path and uses it together with the malfunction time, to reconstruct the current state. To that end, the plan is copied for all timesteps up to malfunction time. Except the malfunctioning trains and trains which collide with them. For those the last action fails and one less is copied. 

\textit{Persisting} computes how long a train malfunctions and derives persistent information which will never be violated even if another malfunction happens in the next timestep.

\textit{Recompute} repeats the pathfinding computation with a shifted window. The window starts at the malfunction timesteps and exceeds the old window by the duration of the worst malfunction at the timestep. This assumes the worst case, as a malfunction for 5 timesteps, at worst requires 5 additional timesteps to solve the instance.\\

To save on computation, the secondary encodings do not compute the graph again, but instead get it passed via save/load, thus receiving the derived atoms as input.

\noindent \textbf{Implications} This might lead to an explosion of window size. If multiple trains, successively encounter a malfunction of 1 timestep, while not interfering with one another, they would still require one additional timestep to ensure solvability. Instead, this encoding would add as many timesteps as trains, complicating computation.

As this encoding models the paths by timesteps it scales bad with bigger instances, leading to an explosion in grounding.

Lastly, it might not be optimal but given a good guess for the horizon, it can compute a valid path without any optimality quickly.

\subsection{Naive Graph}
\textbf{Motivation} To ascertain, that passing the graph-predicates instead of just passing the environment-predicates and recomputing it, this encoding was implemented.

\textbf{Implementation} As the secondary encoding receives its sole input from the previous runs it is necessary to load and save the environment predicates on every run. These are then used to compute the graph as well as a solution.

\textbf{Implications} This approach will probably end up being slower. As reading the graph from predicates should be slower than computing it. Other than that it should be quite similar, to the graph approach.

\subsection{Incremental}
\textbf{Motivation} Incremental encodings as described in \cite{incr} allow for incrementally adding timesteps to the grounding until a problem is solvable. The advantage of that is, if the amount of time required to solve a problem is unknown, this allows to solve it and also with the minimal amount of timesteps. The main downside is, that every iteration requires it to prove unsatisfieability before adding the next timestep. Thus, it is mostly applicable, when lacking a good estimate of the horizon.

Nonetheless, this approach should be well suited, for this problem. As instead of being run once, it is run multiple times for every malfunction, where every unnecessary timestep extends the time taken over and over.

The resulting concept is, to use the horizon estimate as the other encodings do, but whenever this leads to unsatisfieability another timestep is added. Thus still using the given estimate, but using the incremental implementation mainly for malfunction handling. In the case of a malfunction it first tries to solve it, without adding timesteps and only adds them if required.\\

\noindent \textbf{Implementation} This required work on the Clingo side. Since the environment given, to run instances, does not allow Clingo to call any python modes from within, I needed to modify the given solve.py. The result can be seen in our GitHub Repository and follows closely the implementation in \cite{incr}.

Next the encoding was separated into steps, as described above. The graph generation and pathfinding up to the first horizon, happened in the first run. Then a stepwise pathfinding (mimicking the other) is implemented for the step and only ever grounds one additional step. And lastly the goal condition of every agent reaching its goal, was implemented in the check part of the program, which is grounded before every solving and removed afterwards.

Other than that. It is an extension of the graph approach and uses the same building and passing of the graph.\\

\noindent \textbf{Implications} As it solves over and over, this encoding should perform worse in some timesteps, where the adding of additional timesteps, is required. But other than that it should, outperform the other encodings. This should hold especially for environments dense in malfunctions, where the worst case assumption should add way to many additional timesteps.